# TargetedANC
ëŠ¥ë™í˜• ë…¸ì´ì¦ˆ ì œì–´(ANC)ëŠ” ì› ì†ŒìŒì— ëŒ€í•œ ë°˜ëŒ€ ìœ„ìƒì„ ìƒì„±í•˜ì—¬ ì†ŒìŒì„ ìƒì‡„í•˜ì§€ë§Œ (1) ì†ŒìŒì˜ ë¹„ì„ í˜• íŠ¹ì„± ë°˜ì˜ ë¶€ì¡±, (2) ì‹ í˜¸ ì²˜ë¦¬ ê³¼ì •ì—ì„œì˜ ì‹œê°„ ì§€ì—°(time latency), (3) ë³µí•© ì†Œë¦¬ì—ì„œì˜ í•„ìš”í•œ ìŒì›ê¹Œì§€ ì €ê°í•œë‹¤ëŠ” í•œê³„ê°€ ì¡´ì¬í•œë‹¤. ì´ì— ë³¸ ì—°êµ¬ì—ì„œëŠ” ë¶„ë¦¬-ì €ê°ì„ End-to-Endë¡œ ê²°í•©í•˜ì—¬ Targeted ANC ëª¨ë¸ì„ ì œì•ˆí•œë‹¤. ë¶„ë¦¬ì˜ ê²½ìš° C-SuDoRM-RF++ ê¸°ë°˜ ì¸ê³¼ì  ë¶„ë¦¬ ëª¨ë¸ë¡œ ë‘ ìŒì›(ì•ˆë‚´ ë°©ì†¡/ì†ŒìŒ ë“±)ìœ¼ë¡œ ë¶„ë¦¬í•œ ë’¤, Audio Segment Classifier(ASC)ê°€ ê° ìŒì›ì„ í™•ë¥ ì ìœ¼ë¡œ ì‹ë³„í•œë‹¤. ì†ŒìŒìœ¼ë¡œ ì‹ë³„ëœ ì‹ í˜¸ë§Œ WaveNet-Volterra Neural Network ê¸°ë°˜ ì €ê° ëª¨ë¸ë¡œ ì „ë‹¬í•˜ì—¬ ë¹„ì„ í˜• íŠ¹ì„±ì„ ê³ ë ¤í•œ anti-noiseë¥¼ ìƒì„±í•œë‹¤. ë³¸ ì—°êµ¬ ê²°ê³¼ë¡œ  ë¶„ë¦¬-ì €ê° End-to-End ëª¨ë¸ì˜ ì§€ì—°ì„ 24.64msë¡œ ë„ì¶œí•˜ì˜€ë‹¤. ë˜í•œ í‰ê·  dBA -35.12 dB, NMSE -43.72dBë¥¼ ê¸°ë¡í•˜ì—¬ ê¸°ì¡´ í•„í„° ê¸°ë°˜ ANC ì—°êµ¬(FxLMS, SFANC) ëŒ€ë¹„ ì„±ëŠ¥ ì†ì‹¤ ì—†ì´ ì§€ì—° ì‹œê°„ì„ ë„ì¶œí•˜ì˜€ë‹¤. ë³¸ ì—°êµ¬ëŠ” ì¤‘Â·ê³ ì£¼íŒŒì˜ ì†ŒìŒê³¼ ë¹„ì„ í˜• íŠ¹ì„±ì„ ë‹¤ë£¨ëŠ” WaveNet-VNN ì €ê°ê³¼ ë³µí•© ì†Œë¦¬ì— ëŒ€í•œ ì†ŒìŒ ë¶„ë¦¬ë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„ íƒì  ì €ê°ì„ ìˆ˜í–‰í•˜ëŠ” ì¸¡ë©´ì—ì„œ ì˜ì˜ê°€ ìˆë‹¤. ì´ëŠ” êµí†µÂ·ëª¨ë¹Œë¦¬í‹°Â·ì›¨ì–´ëŸ¬ë¸” ë””ë°”ì´ìŠ¤ ë“± ì €ì§€ì—° ì†ŒìŒ ì œì–´ê°€ ìš”êµ¬ë˜ëŠ” ë‹¤ì–‘í•œ í˜„ì¥ì— ì ìš©ë  ìˆ˜ ìˆë‹¤.


## Model Architecture
![image](https://github.com/user-attachments/assets/4b1b942b-d494-4a87-baa0-9376238e0d46)

## Setup
```
pip install -r requirements.txt
```

ì‹¤í–‰ í™˜ê²½: Pyhton: 3.11.13 / Torch: 2.6.0 / Torchaudio: 2.6.0 / librosa: 0.11.0 / Soundfile: 0.13.1

---

**Benchmark Dataset**

Demand: https://www.kaggle.com/datasets/chrisfilo/demand

ms_snsd: https://www.kaggle.com/datasets/jiangwq666/ms-snsd


## Training Data
Training Data Download Link : https://drive.google.com/file/d/1odQm9jrT03vR3z78yDJt0k169AYluz3M/view?usp=sharing
<div align="center">
<img src="https://github.com/user-attachments/assets/a02c34e8-2300-44c7-8ad5-4a4dd7f9cf3f" alt="Dataset Analysis Tables" width="600">
</div>

ì´ 36ì‹œê°„ì˜ í•™ìŠµ ë°ì´í„°ì…‹

ì„œìš¸ êµí†µ ê³µì‚¬ì˜ 1~8í˜¸ì„  ì•ˆë‚´ë°©ì†¡ìŒê³¼ AI HUBì˜ ë„ì‹œ ì†ŒìŒ ë°ì´í„°ë¥¼ ì‚¬ìš©

ë¶„ë¦¬(C-SuDoRM-RF++), ë¶„ë¥˜(ASC)ì— ì‚¬ìš©

---

### Airplane Data
Airplane Data Download Link : https://drive.google.com/file/d/1sAq702S0YB-UkHnM5RuQGnYXmg5fniwf/view?usp=sharing

<div align="center">
<img src="https://github.com/user-attachments/assets/19263f40-3618-4bf6-b5b0-6e17ee62fd17" alt="airplane_data_statistic" width="600">
</div>

ì´ 18ì‹œê°„ì˜ í•­ê³µ ë°ì´í„°ì…‹

Simplazaì˜ 74ê°œì˜ í•­ê³µì‚¬ ê¸°ë‚´ ì•ˆì „ ì•ˆë‚´ë°©ì†¡ ìŒì›ê³¼ AI HUBì˜ ë„ì‹œ ì†ŒìŒ ë°ì´í„° ì¤‘ ë¹„í–‰ê¸° ì†ŒìŒ ë°ì´í„°ë¥¼ ì‚¬ìš©

ë¶„ë¦¬(C-SuDoRM-RF++), ë¶„ë¥˜(ASC)ì— ì‚¬ìš©

---

## Inference_Pipeline
**ë¶„ë¦¬, ë¶„ë¥˜, ì €ê° ê° ëª¨ë¸ì˜ Trainingê³¼ Inference ì½”ë“œì´ë©°, ì•„ë˜ì˜ ë‚´ìš©ì€ Command line usage exampleì…ë‹ˆë‹¤.**

**ì‹¤í–‰ í™˜ê²½ì€ Google Colabì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.**  
**ëª¨ë“  out ë° output ì¸ìë“¤ì€ ë¹ˆ ë””ë ‰í† ë¦¬ë¡œ ë¯¸ë¦¬ ì¤€ë¹„í•´ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.**

### C-SuDoRM-RF++ Training Command
```bash
!python /content/drive/MyDrive/TargetedANC/inference_pipeline/C_SudoRM_RF/c_sudormrf_train.py \
  --model_type causal \
  --train "ANNOUNCENOISE" \
  --val "ANNOUNCENOISE" \
  --test "ANNOUNCENOISE" \
  --n_channels 1 \
  -fs 16000 \
  --batch_size 8 \
  --n_epochs 200 \
  --audio_timelength 4. \
  --enc_kernel_size 21 \
  --enc_num_basis 256 \
  --in_channels 512 \
  --out_channels 256 \
  --num_blocks 18 \
  -lr 0.001 \
  --divide_lr_by 3. \
  --patience 10 \
  --early_stop_patience 30 \
  --upsampling_depth 5 \
  --max_num_sources 2 \
  --min_num_sources 2 \
  --zero_pad_audio \
  --normalize_audio \
  -cad 0 \
  --n_jobs 4 \
  -clp <your_checkpoint_dir>
```




### C-SuDoRM-RF++ Inference Command
```bash
!python /content/drive/MyDrive/TargetedANC/inference_pipeline/C_SudoRM_RF/c_sudormrf_inference.py \
  -ckpt /content/drive/MyDrive/TargetedANC/inference_pipeline/C_SudoRM_RF/causal_best.pt \
  --input_dir /content/drive/MyDrive/TargetedANC/inference_testdata \
  --output_dir <your_output_dir>
```

---

### Audio Segment Classifier(ASC) Training Command
```bash
!python /content/drive/MyDrive/TargetedANC/inference_pipeline/ASC/ASC_train.py \
    --train_s1_dir /content/drive/MyDrive/final_data/train/spk1 \
    --train_s2_dir /content/drive/MyDrive/final_data/train/spk2 \
    --val_s1_dir     /content/drive/MyDrive/final_data/val/spk1 \
    --val_s2_dir     /content/drive/MyDrive/final_data/val/spk2 \
    --test_s1_dir    /content/drive/MyDrive/final_data/test/spk1 \
    --test_s2_dir    /content/drive/MyDrive/final_data/test/spk2 \
    --save_path <your_checkpoint_dir> \
    --sr 16000 \
    --window_len 16000 \
    --batch_size 16 \
    --lr 1e-4 \
    --epochs 15
```

### Audio Segment Classifier(ASC) Inference Command
```bash
!python /content/drive/MyDrive/TargetedANC/inference_pipeline/ASC/ASC_inference.py \
  --test_s1_dir <your_broadcast_dir> \
  --test_s2_dir <your_noise_dir> \
  --model_path /content/drive/MyDrive/inference_pipeline/ASC/asc.pth
```

---


### WaveNet-VNNs Training Command
```bash
!python /content/drive/MyDrive/TargetedANC/inference_pipeline/WaveNet_VNNs/train_opt_210.py \
  --config /content/drive/MyDrive/TargetedANC/inference_pipeline/WaveNet_VNNs/cfg_train_opt_210.toml \
  --device 0
```



### WaveNet-VNNs Infernce Command
```bash
!python /content/drive/MyDrive/TargetedANC/inference_pipeline/WaveNet_VNNs/inference_opt.py \
  --model-path /content/drive/MyDrive/TargetedANC/inference_pipeline/WaveNet_VNNs/model.pth \
  --config /content/drive/MyDrive/TargetedANC/inference_pipeline/WaveNet_VNNs/config_opt_210.json \
  --test-data-dir /content/drive/MyDrive/TargetedANC/inference_testdata \
  --output-enh-dir <your_denoise_dir> \
  --output-anti-dir <your_antinoise_dir>
```

---

### EndtoEnd Inference Command
```bash
!python /content/drive/MyDrive/TargetedANC/inference_pipeline/end2end_inference.py \
  --sep_ckpt      /content/drive/MyDrive/TargetedANC/inference_pipeline/C_SudoRM_RF/causal_best.pt \
  --noise_cfg     /content/drive/MyDrive/TargetedANC/inference_pipeline/WaveNet_VNNs/config_opt_210.json \
  --noise_ckpt   /content/drive/MyDrive/TargetedANC/inference_pipeline/WaveNet_VNNs/model.pth \
  --bcd_ckpt      /content/drive/MyDrive/TargetedANC/inference_pipeline/ASC/asc.pth \
  --input_dir     /content/drive/MyDrive/TargetedANC/inference_testdata \
  --sep_out      <your_seperation_dir> \
  --noise_out       <your_noise_dir> \
  --denoise_out      <your_denoise_dir> \
  --anti_out     <your_antinoise_dir> \
  --final_out   <your_final_dir>
```

## Joint Inference Examples

Joint/colab_Inference_Example.ipynb ë¥¼ í†µí•´ test dataë¡œ joint ì¶”ë¡  ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Mix: ë³µí•© ì†Œë¦¬ / Final: ë¶„ë¦¬ + ì €ê°ëœ ì†ŒìŒ

![image](https://github.com/user-attachments/assets/6967239f-373c-4a39-a5f1-7bad2dfaafa9)

## Streamlit Preview

```
cd Streamlit
```

```
streamlit run Streamlit_test.py
```

ANC ON
![image](https://github.com/user-attachments/assets/4b80772f-9d8e-4670-9cd4-cd5e3fd038fe)

ANC OFF
![image](https://github.com/user-attachments/assets/1b540c31-7870-4d67-bec9-7eed90a0b9b2)


## References

C-SudoRMRF++:
https://github.com/etzinis/sudo_rm_rf

WaveNet-VNNs:
https://github.com/Lu-Baihh/WaveNet-VNNs-for-ANC
- í…ŒìŠ¤íŠ¸ ì»¤ë°‹ (ê¶Œí•œ í™•ì¸ìš©) ğŸ‰
