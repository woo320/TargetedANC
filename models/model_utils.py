"""
ëª¨ë¸ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì¶”ë¡  ìŠ¤íƒ€ì¼ ì§€ì›)
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
import os
from config.constants import SR

def sisdr_loss(est, target, zero_mean=True, eps=1e-9):
    """SI-SDR loss ê³„ì‚°"""
    if est.dim() == 3:
        est = est.squeeze(1)
    if target.dim() == 3:
        target = target.squeeze(1)

    if zero_mean:
        est = est - est.mean(dim=-1, keepdim=True)
        target = target - target.mean(dim=-1, keepdim=True)

    dot = torch.sum(est * target, dim=-1, keepdim=True)
    energy = torch.sum(target**2, dim=-1, keepdim=True) + eps
    proj = (dot / energy) * target
    noise = est - proj

    sisdr = 10 * torch.log10((proj.pow(2).sum(-1) + eps) / (noise.pow(2).sum(-1) + eps))
    return -sisdr.mean()

def load_sudormrf_weights(model, checkpoint_path):
    """SudoRM-RF ê°€ì¤‘ì¹˜ ë¡œë“œ ìœ í‹¸ë¦¬í‹°"""
    state = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

    if 'model_state_dict' in state:
        actual_state = state['model_state_dict']
    elif 'model' in state:
        actual_state = state['model']
    else:
        actual_state = state

    # module. ì ‘ë‘ì‚¬ ì œê±°
    if any(key.startswith('module.') for key in actual_state.keys()):
        new_state = {key[7:] if key.startswith('module.') else key: value
                    for key, value in actual_state.items()}
        actual_state = new_state

    model.load_state_dict(actual_state)
    return model

def load_wavenet_weights(model, checkpoint_path):
    """WaveNet ê°€ì¤‘ì¹˜ ë¡œë“œ ìœ í‹¸ë¦¬í‹°"""
    state = torch.load(checkpoint_path, map_location='cpu')
    model_state = state['model'] if 'model' in state else state
    model.load_state_dict(model_state)
    return model

def load_broadcast_classifier_weights(model, checkpoint_path):
    """BroadcastClassifier ê°€ì¤‘ì¹˜ ë¡œë“œ ìœ í‹¸ë¦¬í‹°"""
    if not os.path.exists(checkpoint_path):
        print(f"âš ï¸ BroadcastClassifier checkpoint not found: {checkpoint_path}")
        print("   Using randomly initialized weights")
        return model
    
    try:
        state = torch.load(checkpoint_path, map_location='cpu')
        model.load_state_dict(state)
        print(f"âœ… BroadcastClassifier weights loaded from: {checkpoint_path}")
        return model
    except Exception as e:
        print(f"âŒ Error loading BroadcastClassifier weights: {e}")
        print("   Using randomly initialized weights")
        return model

def prepare_audio_for_classifier(audio, window_len=16000):
    """
    ë¶„ë¥˜ê¸°ìš© ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
    
    Args:
        audio: (B, C, T) í˜•íƒœì˜ ì˜¤ë””ì˜¤
        window_len: ë¶„ë¥˜ê¸° ì…ë ¥ ê¸¸ì´
    
    Returns:
        processed_audio: (B, 1, window_len) í˜•íƒœ
    """
    # ì°¨ì› ì¡°ì •
    if audio.dim() == 3:
        audio = audio.squeeze(1)  # (B, T)
    elif audio.dim() == 1:
        audio = audio.unsqueeze(0)  # (1, T)
    
    batch_size, seq_len = audio.shape
    
    # ê¸¸ì´ ì¡°ì •
    if seq_len > window_len:
        # ì¤‘ì•™ ë¶€ë¶„ ì¶”ì¶œ
        start_idx = (seq_len - window_len) // 2
        audio = audio[:, start_idx:start_idx + window_len]
    elif seq_len < window_len:
        # íŒ¨ë”©
        pad_len = window_len - seq_len
        audio = F.pad(audio, (0, pad_len), mode='constant', value=0)
    
    # (B, 1, T) í˜•íƒœë¡œ ë³€í™˜
    return audio.unsqueeze(1)

# ===== ğŸ”„ ë¶„ë¥˜ ì†ì‹¤ í•¨ìˆ˜ë“¤ =====

def compute_broadcast_classification_loss(classification_output, s1_separated, s2_separated, bce_loss_fn, device):
    """
    ğŸ”§ í•™ìŠµ ì½”ë“œ í˜¸í™˜ìš© í†µí•© ë¶„ë¥˜ ì†ì‹¤ í•¨ìˆ˜
    ì¶”ë¡  ìŠ¤íƒ€ì¼ê³¼ í…ì„œ ìŠ¤íƒ€ì¼ ëª¨ë‘ ì§€ì›
    """
    if classification_output is None:
        return torch.tensor(0.0, device=device), 0.0
    
    # ğŸ“‹ ì¼€ì´ìŠ¤ 1: ì¶”ë¡  ìŠ¤íƒ€ì¼ (ë”•ì…”ë„ˆë¦¬)
    if isinstance(classification_output, dict) and 'batch_info' in classification_output:
        return compute_broadcast_classification_loss_inference_style(
            classification_output, s1_separated, s2_separated, bce_loss_fn, device
        )
    
    # ğŸ“‹ ì¼€ì´ìŠ¤ 2: í…ì„œ ìŠ¤íƒ€ì¼ (ê¸°ì¡´ ë°©ì‹)
    elif hasattr(classification_output, 'shape') and hasattr(classification_output, 'dim'):
        try:
            # íƒ€ê²Ÿ ìƒì„±: s1ê³¼ s2ì˜ ì—ë„ˆì§€ ë¹„êµ
            s1_energy = torch.mean(s1_separated.abs(), dim=-1)
            s2_energy = torch.mean(s2_separated.abs(), dim=-1)
            targets = (s1_energy > s2_energy).float().squeeze(-1)
            
            # BCE ì†ì‹¤ ê³„ì‚°
            classification_loss = bce_loss_fn(
                classification_output.squeeze(-1) if classification_output.dim() > 1 else classification_output,
                targets
            )
            
            # ì •í™•ë„ ê³„ì‚°
            probs = torch.sigmoid(classification_output.squeeze())
            predicted = (probs > 0.5).float()
            accuracy = (predicted == targets).float().mean().item()
            
            return classification_loss, accuracy
            
        except Exception as e:
            print(f"âš ï¸ Tensor-style classification loss calculation failed: {e}")
            return torch.tensor(0.0, device=device), 0.0
    
    # ğŸ“‹ ì¼€ì´ìŠ¤ 3: ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹
    else:
        print(f"âš ï¸ Unknown classification output type: {type(classification_output)}")
        return torch.tensor(0.0, device=device), 0.0

def compute_broadcast_classification_loss_inference_style(
    classification_results, s1_target, s2_target, bce_loss_fn, device
):
    """
    ì¶”ë¡  ë°©ì‹ì˜ ë¶„ë¥˜ ì†ì‹¤ ê³„ì‚°
    
    Args:
        classification_results: joint modelì˜ ë¶„ë¥˜ ê²°ê³¼
        s1_target: Ground truth s1 (ë°©ì†¡)
        s2_target: Ground truth s2 (ì†ŒìŒ)
        bce_loss_fn: BCEWithLogitsLoss
        device: torch device
    
    Returns:
        classification_loss: ë¶„ë¥˜ ì†ì‹¤
        accuracy: ì •í™•ë„
    """
    if 'batch_info' not in classification_results:
        return torch.tensor(0.0, device=device), 0.0
    
    batch_info = classification_results['batch_info']
    batch_size = len(batch_info)
    
    total_loss = 0.0
    correct_classifications = 0
    
    for b, info in enumerate(batch_info):
        # Ground truth: s1ì€ ë°©ì†¡(1), s2ëŠ” ì†ŒìŒ(0)
        chan0_prob = info['mask_chan0']  # ì±„ë„0ì˜ ë°©ì†¡ í™•ë¥ 
        chan1_prob = info['mask_chan1']  # ì±„ë„1ì˜ ë°©ì†¡ í™•ë¥ 
        
        # í™•ë¥ ì„ logitìœ¼ë¡œ ë³€í™˜ (ì•ˆì „í•œ ë°©ë²•)
        chan0_prob = max(0.001, min(0.999, chan0_prob))  # í´ë¦¬í•‘
        chan1_prob = max(0.001, min(0.999, chan1_prob))
        
        chan0_logit = torch.log(torch.tensor(chan0_prob / (1 - chan0_prob), device=device))
        chan1_logit = torch.log(torch.tensor(chan1_prob / (1 - chan1_prob), device=device))
        
        # Ground truth ë¼ë²¨
        chan0_target = torch.tensor(1.0, device=device)  # s1ì€ ë°©ì†¡
        chan1_target = torch.tensor(0.0, device=device)  # s2ëŠ” ì†ŒìŒ
        
        # BCE ì†ì‹¤ ê³„ì‚°
        loss0 = bce_loss_fn(chan0_logit.unsqueeze(0), chan0_target.unsqueeze(0))
        loss1 = bce_loss_fn(chan1_logit.unsqueeze(0), chan1_target.unsqueeze(0))
        
        total_loss += (loss0 + loss1) / 2
        
        # ì •í™•ë„: ì±„ë„0(s1)ì´ ë” ë†’ì€ í™•ë¥ ì„ ê°€ì ¸ì•¼ í•¨
        predicted_correctly = (chan0_prob > chan1_prob)
        if predicted_correctly:
            correct_classifications += 1
    
    avg_loss = total_loss / batch_size
    accuracy = correct_classifications / batch_size
    
    return avg_loss, accuracy

def compute_classification_reward_penalty(classification_results, device):
    """
    ë¶„ë¥˜ ì •í™•ë„ì— ë”°ë¥¸ ë³´ìƒ/í˜ë„í‹° ê³„ì‚°
    
    Args:
        classification_results: joint modelì˜ ë¶„ë¥˜ ê²°ê³¼
        device: torch device
    
    Returns:
        reward_penalty: ë³´ìƒ(ìŒìˆ˜)/í˜ë„í‹°(ì–‘ìˆ˜) ê°’
    """
    if not isinstance(classification_results, dict) or 'batch_info' not in classification_results:
        return torch.tensor(0.0, device=device)
    
    batch_info = classification_results['batch_info']
    batch_size = len(batch_info)
    
    total_penalty = 0.0
    
    for info in batch_info:
        chan0_prob = info['mask_chan0']
        chan1_prob = info['mask_chan1']
        
        # Ground truth: ì±„ë„0(s1)ì´ ë°©ì†¡, ì±„ë„1(s2)ì´ ì†ŒìŒ
        correct_classification = (chan0_prob > chan1_prob)
        
        if correct_classification:
            total_penalty -= 0.1  # ì‘ì€ ë³´ìƒ
        else:
            total_penalty += 0.5   # í° í˜ë„í‹°
    
    return torch.tensor(total_penalty / batch_size, device=device)

# ===== ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ =====

def compute_anc_losses(s2_enhanced, s2_target, dba_loss_fn, nmse_loss_fn, device):
    """ANC ì†ì‹¤ ê³„ì‚° ìœ í‹¸ë¦¬í‹°"""
    try:
        s2_enhanced_flat = s2_enhanced.squeeze(1)
        s2_target_flat = s2_target.squeeze(1)

        anc_dba_loss = dba_loss_fn(s2_enhanced_flat) - dba_loss_fn(s2_target_flat)
        anc_nmse_loss = nmse_loss_fn(s2_enhanced_flat, s2_target_flat)
    except Exception:
        anc_dba_loss = torch.tensor(0.0, device=device)
        anc_nmse_loss = torch.tensor(0.0, device=device)
    
    return anc_dba_loss, anc_nmse_loss

def compute_loss_weights(use_dynamic_mix=False):
    """ì†ì‹¤ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    if use_dynamic_mix:
        # SudoRM-RF: ë¶„ë¦¬ í’ˆì§ˆì´ ë” ì¤‘ìš”
        return {
            'final_quality': 0.25,     # 25%
            'anc_total': 0.35,         # 35%
            's1_separation': 0.3,      # 30% (ì¦ê°€)
            'antinoise_constraint': 0.1 # 10%
        }
    else:
        # ê¸°ì¡´ pre-mixed: ANC ì¤‘ì‹¬
        return {
            'final_quality': 0.3,      # 30%
            'anc_total': 0.4,          # 40%
            's1_separation': 0.2,      # 20%
            'antinoise_constraint': 0.1 # 10%
        }

def create_loss_functions(device, fs=16000, nfft=512):
    """ì†ì‹¤ í•¨ìˆ˜ë“¤ ìƒì„±"""
    # WaveNet ê²½ë¡œ ì¶”ê°€
    sys.path.insert(0, "/content/drive/MyDrive/joint/WaveNet-VNNs-for-ANC/WaveNet_VNNs")
    from loss_function import dBA_Loss, NMSE_Loss
    
    dba_loss = dBA_Loss(fs=fs, nfft=nfft, f_up=fs/2).to(device)
    nmse_loss = NMSE_Loss().to(device)
    
    return dba_loss, nmse_loss

def setup_optimizer_groups(separation_model, noise_model, eta_param, config):
    """ì˜µí‹°ë§ˆì´ì € íŒŒë¼ë¯¸í„° ê·¸ë£¹ ì„¤ì •"""
    separation_params = list(separation_model.parameters())
    noise_params = list(noise_model.parameters())
    eta_params = [eta_param] if eta_param is not None else []

    param_groups = [
        {'params': separation_params, 'lr': config.get('separation_lr', 5e-6)},
        {'params': noise_params, 'lr': config.get('noise_lr', 1e-5)},
    ]

    if eta_params:
        param_groups.append({'params': eta_params, 'lr': config.get('eta_lr', 2e-5)})

    return param_groups

def get_training_stages(total_epochs):
    """í•™ìŠµ ë‹¨ê³„ ì •ì˜"""
    return {
        "Initial Adaptation": {
            "range": f"1-{min(3, total_epochs//3)}",
            "description": "Models learning to cooperate"
        },
        "Stabilization": {
            "range": f"{min(4, total_epochs//3 + 1)}-{min(total_epochs*2//3, total_epochs-2)}",
            "description": "Gradual ANC optimization"
        },
        "Fine Convergence": {
            "range": f"{max(total_epochs*2//3 + 1, total_epochs-1)}-{total_epochs}",
            "description": "Final tuning and convergence"
        }
    }

def get_current_stage(epoch, total_epochs):
    """í˜„ì¬ í•™ìŠµ ë‹¨ê³„ ë°˜í™˜"""
    if epoch <= total_epochs // 3:
        return "Initial Adaptation"
    elif epoch <= total_epochs * 2 // 3:
        return "Stabilization"
    else:
        return "Fine Convergence"

def ensure_audio_length(arr, target_len):
    """ì˜¤ë””ì˜¤ ê¸¸ì´ ë³´ì • ìœ í‹¸ë¦¬í‹°"""
    import numpy as np
    
    if isinstance(arr, np.ndarray) and arr.ndim > 0:
        return arr[:target_len] if len(arr) >= target_len else np.pad(arr, (0, target_len - len(arr)), 'constant')
    else:
        return np.full(target_len, float(arr) if np.isscalar(arr) else 0.0)

def normalize_audio_for_save(audio_array, target_db=-20):
    """ì €ì¥ìš© ì˜¤ë””ì˜¤ ì •ê·œí™”"""
    import numpy as np
    
    if isinstance(audio_array, torch.Tensor):
        audio_array = audio_array.squeeze().cpu().numpy()

    if len(audio_array) > 0:
        audio_power = np.mean(audio_array ** 2) + 1e-9
        audio_db = 10 * np.log10(audio_power)
        gain_db = target_db - audio_db
        gain_linear = 10 ** (gain_db / 20)
        normalized = np.clip(audio_array * gain_linear, -1.0, 1.0)
        return normalized
    else:
        return audio_array

def check_overfitting(train_metric, val_metric, threshold=1.3):
    """ì˜¤ë²„í”¼íŒ… ì²´í¬ (ìŒìˆ˜ ì†ì‹¤ ê³ ë ¤)"""
    return abs(train_metric) > abs(val_metric) * threshold

def calculate_snr_improvement(input_audio, enhanced_audio, eps=1e-9):
    """SNR ê°œì„ ë„ ê³„ì‚°"""
    input_power = torch.mean(input_audio ** 2)
    enhanced_power = torch.mean(enhanced_audio ** 2)
    snr_improvement = 10 * torch.log10(enhanced_power / (input_power + eps))
    return snr_improvement.item()

def format_memory_info(allocated_gb, reserved_gb, total_gb=None):
    """ë©”ëª¨ë¦¬ ì •ë³´ í¬ë§·íŒ…"""
    info = f"{allocated_gb:.1f}GB allocated, {reserved_gb:.1f}GB reserved"
    if total_gb:
        info += f" (Total: {total_gb:.1f}GB)"
    return info

def setup_cuda_environment():
    """CUDA í™˜ê²½ ìµœì í™” ì„¤ì •"""
    import os
    
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = False
        torch.backends.cudnn.deterministic = True
        
        # íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256,expandable_segments:True'
        
        return True
    return False

def get_device_info():
    """ë””ë°”ì´ìŠ¤ ì •ë³´ ë°˜í™˜"""
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name()
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        return device_name, total_memory
    else:
        return "CPU", 0.0